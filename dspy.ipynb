{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSPy on Azure OpenAI - 241026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AzureOpenAI endpoints \n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "deployment='gpt-4o-eastus-0806'\n",
    "\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_EASTUS_API_KEY\"),  \n",
    "    api_version=\"2024-06-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_API_EASTUS_ENDPOINT\")\n",
    "    )\n",
    "        \n",
    "# Send a completion call to generate an answer\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages = [\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an MIT PhD in Physics, specializing in quantum physics.\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is a black hole?\"\n",
    "        }\n",
    "    ]\n",
    "    # max_tokens=4096\n",
    ")\n",
    "\n",
    "#print(completion.model_dump_json(indent=2))\n",
    "content = completion.choices[0].message.content\n",
    "print(content)\n",
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM('openai/gpt-4o-mini-eastus-0718')\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "qa = dspy.Predict('question: str -> response: str')\n",
    "qa(question=\"what are high memory and low memory on linux?\").response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config=dotenv_values(\".env\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_API_EASTUS_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_EASTUS_API_KEY\")\n",
    "embedding_model=\"text-embedding-3-small-eastus\"\n",
    "deployment='gpt-4o-eastus-0806'\n",
    "\n",
    "import dspy\n",
    "\n",
    "turbo = dspy.AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version= \"2024-06-01\",\n",
    "    api_base=azure_endpoint,\n",
    "    model=deployment,\n",
    ")\n",
    "\n",
    "dspy.configure(lm=turbo)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"High memory and low memory in Linux refer to different regions of the system's RAM. Low memory is directly accessible by the kernel and is typically the first 896 MB on a 32-bit system. High memory is the rest of the RAM that requires special handling to be accessed by the kernel. This distinction is more relevant in 32-bit systems due to their limited address space. In 64-bit systems, the distinction is less significant because they can address much larger amounts of memory directly.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = dspy.Predict('question: str -> response: str')\n",
    "qa(question=\"what are high memory and low memory on linux?\").response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
